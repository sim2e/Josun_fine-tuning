{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "533c1622-85f0-4c03-ac18-d6142cfc9552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in ./anaconda3/lib/python3.8/site-packages (1.3.3)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in ./anaconda3/lib/python3.8/site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./anaconda3/lib/python3.8/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./anaconda3/lib/python3.8/site-packages (from openai) (0.25.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./anaconda3/lib/python3.8/site-packages (from openai) (1.10.11)\n",
      "Requirement already satisfied: tqdm>4 in ./anaconda3/lib/python3.8/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in ./anaconda3/lib/python3.8/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./anaconda3/lib/python3.8/site-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./anaconda3/lib/python3.8/site-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in ./anaconda3/lib/python3.8/site-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
      "Requirement already satisfied: certifi in ./anaconda3/lib/python3.8/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Requirement already satisfied: httpcore<0.19.0,>=0.18.0 in ./anaconda3/lib/python3.8/site-packages (from httpx<1,>=0.23.0->openai) (0.18.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./anaconda3/lib/python3.8/site-packages (from httpcore<0.19.0,>=0.18.0->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "cd6959b9-0abe-4018-ab05-6c2a0b8727b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-RTgPmc8gMkKVWbY7wN7YTw10', bytes=354466, created_at=1700391952, filename='5_kings_transformed_final.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai._client import OpenAI\n",
    "\n",
    "client = OpenAI(api_key='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')\n",
    "\n",
    "client.files.create(\n",
    "    file = open(\"5_kings_transformed_final.jsonl\", \"rb\"),\n",
    "    purpose = 'fine-tune'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "37de52ad-5bb5-4fa9-9790-c3af4b9c2c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-2gsa766UPqu4QKGu0wHfjMFy', created_at=1700397856, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-1106', object='fine_tuning.job', organization_id='org-GPPtiBmELuROX9JO6rIKfhEL', result_files=[], status='validating_files', trained_tokens=None, training_file='file-RTgPmc8gMkKVWbY7wN7YTw10', validation_file=None)"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.create(\n",
    "  training_file=\"file-RTgPmc8gMkKVWbY7wN7YTw10\", \n",
    "  model=\"gpt-3.5-turbo-1106\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "8f0138f8-b703-4cfb-8c4d-2a3327161f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-2gsa766UPqu4QKGu0wHfjMFy', created_at=1700397856, error=None, fine_tuned_model='ft:gpt-3.5-turbo-1106:personal::8MbvPLZQ', finished_at=1700399690, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-1106', object='fine_tuning.job', organization_id='org-GPPtiBmELuROX9JO6rIKfhEL', result_files=['file-JtwOKKlPlzrBbwmBZNrIIq3g'], status='succeeded', trained_tokens=230916, training_file='file-RTgPmc8gMkKVWbY7wN7YTw10', validation_file=None)"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.list(limit=10)\n",
    "client.fine_tuning.jobs.retrieve(\"ftjob-2gsa766UPqu4QKGu0wHfjMFy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "c2550e90-859d-464d-98fc-61076c31ddd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kanghwa Island.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"ft:gpt-3.5-turbo-1106:personal::8MbvPLZQ\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are an helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where did the Wihwado Retreat occurred?\"}\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "a0baf32c-d30b-47e5-901c-0d03b05517b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelDeleted(id='ft:gpt-3.5-turbo-0613:personal::8MUzexO5', deleted=True, object='model')"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# client.models.delete(\"ft:gpt-3.5-turbo-0613:personal::8MUzexO5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "53cdd0ec-e05d-4cb1-85c4-64940b2680e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0.5\n",
      "0\n",
      "0\n",
      "0\n",
      "0.5\n",
      "0\n",
      "0.2\n",
      "0\n",
      "0\n",
      "0.5\n",
      "0.5\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.26812801841425576\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.2222222222222222\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.5\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.5\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.5\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.027891270018553734\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.5\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.3333333333333333\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.5\n",
      "0.13406400920712788\n",
      "0.5\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.47768754038252614\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.3333333333333333\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.5\n",
      "0.07142857142857141\n",
      "0.0410424993119494\n",
      "0\n",
      "0.0410424993119494\n",
      "0\n",
      "0.5\n",
      "0.5\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.25\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.5\n",
      "0\n",
      "0.0410424993119494\n",
      "0.5\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import nltk.translate.bleu_score as bleu\n",
    "\n",
    "with open('5_kings_all.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "scores = []\n",
    "answers = []\n",
    "for i in data:\n",
    "    rf_answer_list =[]\n",
    "\n",
    "    question = i['question']\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"ft:gpt-3.5-turbo-1106:personal::8MbvPLZQ\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{question}\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    answer = response.choices[0].message.content\n",
    "    answers.append(answer)\n",
    "\n",
    "    for j in data:\n",
    "        if j['question'] == question:\n",
    "            rf_answer_list.append(j['answer'])\n",
    "\n",
    "    result = list(map(lambda ref : ref.split(), rf_answer_list))\n",
    "\n",
    "    score = bleu.sentence_bleu(result, answer.split(), weights=(1, 0, 0, 0))\n",
    "    print(score)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "3aff9626-b8e5-41b2-9d60-bf79cf2f6187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.043793902186236876\n"
     ]
    }
   ],
   "source": [
    "for i in answers:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278cf922-b8bf-4017-b721-45f34b38ea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "average = sum(scores) / len(scores)\n",
    "print(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "fe9a4aec-aec5-4924-b76d-b7b887228a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Wihwado Retreat occurred on Wihwa Island in South Korea. It was an important event in Korean history, as it led to the establishment of the Goryeo dynasty.\n"
     ]
    }
   ],
   "source": [
    "response2 = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where did the Wihwado Retreat occurred?\"}\n",
    "    ]\n",
    ")\n",
    "print(response2.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c87d1-2089-491a-b46e-da259eaadd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10344827586206899\n",
      "0.10344827586206899\n",
      "0.10344827586206899\n",
      "0.043478260869565216\n",
      "0.030303030303030304\n",
      "0\n",
      "0\n",
      "0.0588235294117647\n",
      "0.012048192771084333\n",
      "0.10344827586206899\n",
      "0\n",
      "0.011363636363636359\n",
      "0\n",
      "0.09523809523809525\n",
      "0\n",
      "0.0588235294117647\n",
      "0\n",
      "0.03571428571428572\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.04545454545454546\n",
      "0.0588235294117647\n",
      "0.05000000000000001\n",
      "0.06666666666666667\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.023809523809523808\n",
      "0.03125\n",
      "0.03846153846153846\n",
      "0\n",
      "0.040540540540540536\n",
      "0.06451612903225806\n",
      "0.03846153846153846\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.043478260869565216\n",
      "0\n",
      "0.0588235294117647\n",
      "0.07272727272727272\n",
      "0.04597701149425288\n",
      "0.06779661016949153\n",
      "0.028571428571428577\n",
      "0\n",
      "0\n",
      "0\n",
      "0.10000000000000002\n",
      "0.03448275862068965\n",
      "0.06493506493506493\n",
      "0.05970149253731344\n",
      "0.028571428571428577\n",
      "0.03846153846153846\n",
      "0.10000000000000002\n",
      "0.07142857142857141\n",
      "0\n",
      "0\n",
      "0.041666666666666664\n",
      "0.11111111111111109\n",
      "0.04545454545454546\n",
      "0.12000000000000001\n",
      "0.03921568627450981\n",
      "0.03571428571428572\n",
      "0.06451612903225806\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.05555555555555554\n",
      "0\n",
      "0\n",
      "0.05263157894736841\n",
      "0\n",
      "0\n",
      "0.037037037037037035\n",
      "0\n",
      "0\n",
      "0.03448275862068965\n",
      "0.07142857142857141\n",
      "0\n",
      "0\n",
      "0\n",
      "0.037037037037037035\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.03225806451612903\n",
      "0.03846153846153846\n",
      "0.020408163265306117\n",
      "0\n",
      "0\n",
      "0.03333333333333333\n",
      "0\n",
      "0\n",
      "0.08333333333333333\n",
      "0.05000000000000001\n",
      "0.27906976744186046\n",
      "0.023809523809523808\n",
      "0\n",
      "0\n",
      "0.025641025641025644\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.047619047619047616\n",
      "0.11111111111111109\n",
      "0.07142857142857141\n",
      "0\n",
      "0\n",
      "0.02777777777777778\n",
      "0.08823529411764706\n",
      "0\n",
      "0\n",
      "0.028571428571428577\n",
      "0\n",
      "0\n",
      "0.0588235294117647\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.013888888888888888\n",
      "0\n",
      "0.05555555555555554\n",
      "0\n",
      "0\n",
      "0.030303030303030304\n",
      "0\n",
      "0\n",
      "0.024390243902439022\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import nltk.translate.bleu_score as bleu\n",
    "\n",
    "with open('5_kings_all.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "num_2 = []\n",
    "answers = []\n",
    "for i in data:\n",
    "    rf_answer_list =[]\n",
    "\n",
    "    question = i['question']\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{question}\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    answer = response.choices[0].message.content\n",
    "    answers.append(answer)\n",
    "\n",
    "    for j in data:\n",
    "        if j['question'] == question:\n",
    "            rf_answer_list.append(j['answer'])\n",
    "\n",
    "    result = list(map(lambda ref : ref.split(), rf_answer_list))\n",
    "\n",
    "    score = bleu.sentence_bleu(result, answer.split(), weights=(1, 0, 0, 0))\n",
    "    num_2.append(score)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b043c741-644a-4eb4-b1e3-0351b5258ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85572a21-f0a9-4f75-b66b-d720493c5eac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "average_2 = sum(num_2) / len(num_2)\n",
    "print(average_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230484c1-e29d-4feb-af68-e68dd1638a26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
